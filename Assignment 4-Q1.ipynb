{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,Y,b,W,reg):\n",
    "    y_hat=np.dot(X,W)+np.transpose(b)\n",
    "    m=X.shape[0]\n",
    "    mse =1/m* np.sum(np.square((Y - y_hat)**2))\n",
    "    Loss=mse+ reg*np.sum(W**2)\n",
    "    cache={\"y_hat\":y_hat}\n",
    "    return Loss,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_prop(W,X,Y,Y_hat,reg):\n",
    "    m=Y.shape[0]\n",
    "    dy_hat =Y_hat-Y\n",
    "    dW =(1/float(m))*(np.dot(X.T, dy_hat)+reg*W)\n",
    "    db=(1/float(m))*np.sum(dy_hat,axis=0)\n",
    "    return dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    y_hat = np.argmax(y_hat,axis=1)\n",
    "    y= np.argmax(y,axis=1)\n",
    "    accuracy=np.sum(y_hat==y)/y.size \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print('x_train:' , x_train.shape)\n",
    "print('x_test:' , x_test.shape)\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "# Din = 784 # MINIST\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "#https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current\n",
    "x_test = x_test - mean_image\n",
    "\"\"\"In the ytrain it is preliminarily is in numbers just to indicate the particular class tf.keras.utils.to_categorical(y_train, num_classes=K) does is \n",
    "Converting the number to a binary vector\n",
    "Ex: \n",
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)\n",
    "tf.Tensor(\n",
    "[[1. 0. 0. 0.]\n",
    " [0. 1. 0. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
    "\"\"\"\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "x_train = np.reshape(x_train,(Ntr,Din))#shaping images into a vector Din=32x32x3\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, K)#initialization\n",
    "b1 = np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "batch_size = Ntr #for the batch size whole dataset is considered\n",
    "\n",
    "iterations =300\n",
    "lr =0.035\n",
    "lr_decay=0#learning rate is decreased in each iteration\n",
    "reg =0#regularization term which stops growth of weights\n",
    "train_loss_history = []\n",
    "test_loss_history=[]\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    #indices = np.arange(Ntr)#generating image\n",
    "    #rng.shuffle(indices)\n",
    "    # Forward pass\n",
    "    loss,cache=forward_prop(W=w1,b=b1,X=x_train,Y=y_train,reg=reg)\n",
    "    train_loss_history.append(loss)\n",
    "    y_hat=cache[\"y_hat\"]\n",
    "    train_acc=1.0-Ntr*(np.abs(np.argmax(y_train,axis=1)-np.argmax(y_hat,axis=1))).sum()\n",
    "    train_acc_history.append(train_acc)\n",
    "    # Backward pass\n",
    "    dw1,db1=back_prop(Y_hat=y_hat,W=w1,X=x_train,Y=y_train,reg=reg)\n",
    "    w1=w1-lr*dw1\n",
    "    b1=b1-lr*db1\n",
    "    lr=lr/(1+t*lr_decay)\n",
    "    \n",
    "    test_loss,cache_test=forward_prop(W=w1,b=b1,X=x_test,Y=y_test,reg=reg)\n",
    "    cache_test[\"y_hat\"]=y_test_hat\n",
    "    test_acc=1.0-Ntr*(np.abs(np.argmax(y_train,axis=1)-np.argmax(y_test_hat,axis=1))).sum()\n",
    "    test_acc_history.append(test_acc)\n",
    "    if t%10==0:\n",
    "        print(\"Epoch \"+str(t+1)+\"/\"+str(iterations)+\">>> trainig_loss: \",loss,\">>training_accuracy: \",train_acc,\"testing_loss:\",test_loss,\"testing_accuracy:\",test_acc)\n",
    "# Printing accuracies and displaying w as images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
      "[1.5 0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)\n",
    "B=[[1,2,1,1],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "mse = np.mean((a - B)**2,axis=1)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "def loss(W,b,X,Y,reg):\n",
    "    print(W.shape,\"W\")\n",
    "    print(b.shape,\"b\")\n",
    "    print(X.shape,\"X\")\n",
    "    print(Y.shape,\"Y\")\n",
    "    prediction=np.dot(X,W)+np.transpose(b)\n",
    "    print()\n",
    "    m=X.shape[0]\n",
    "    mse = np.sum(np.square((Y - prediction)**2))\n",
    "    Loss=mse+ 1/(2*m)*reg*np.sum(W**2)\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.73105858, 0.88079708, 0.73105858, 0.73105858],\n",
       "       [0.5       , 0.73105858, 0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       , 0.73105858, 0.5       ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.73105858]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    z=np.array(z)\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "sigmoid(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.49998923857004474\n"
     ]
    }
   ],
   "source": [
    "loss,cache=forward_prop(W=w1,b=b1,X=x_train,Y=y_train,reg=reg)\n",
    "print(loss)\n",
    "y_hat=cache[\"y_hat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[-5.60294253e-03, -2.38228143e-03,  2.25626789e-03, ...,\n",
       "         -1.66584013e-03, -6.09623615e-03, -1.43466064e-02],\n",
       "        [-9.87432428e-03, -8.76206678e-04,  1.98903826e-03, ...,\n",
       "         -2.10664917e-03, -1.04874780e-02, -1.61687181e-02],\n",
       "        [-1.79099455e-02, -1.37219492e-03,  6.71838721e-03, ...,\n",
       "         -1.92025827e-03, -1.81712554e-02, -2.04092694e-02],\n",
       "        ...,\n",
       "        [-1.25619369e-03, -2.77595903e-03,  5.82931016e-04, ...,\n",
       "         -5.32556245e-03,  1.18562262e-02, -5.05095503e-03],\n",
       "        [-3.97208294e-03, -2.21981253e-03, -4.58652880e-05, ...,\n",
       "         -3.55784550e-03,  6.31214200e-03, -3.90185596e-03],\n",
       "        [-9.14413372e-03, -4.84109105e-03,  2.94591984e-03, ...,\n",
       "          2.34340162e-03, -1.38188891e-03, -5.50754172e-03]]),\n",
       " array([-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "back_prop(Y_hat=y_hat,W=w1,X=x_train,Y=y_train,reg=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
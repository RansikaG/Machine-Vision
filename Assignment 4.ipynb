{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "w1: (3072, 10)\n",
      "b1: (10,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nseed = 0\\nrng = np.random.default_rng(seed=seed)\\nfor t in range(iterations):\\n    indices = np.arange(Ntr)#generating image\\n    rng.shuffle(indices)\\n    # Forward pass\\n    # Backward pass\\n# Printing accuracies and displaying w as images\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print('x_train:' , x_train.shape)\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "# Din = 784 # MINIST\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "#https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current\n",
    "x_test = x_test - mean_image\n",
    "\"\"\"In the ytrain it is preliminarily is in numbers just to indicate the particular class tf.keras.utils.to_categorical(y_train, num_classes=K) does is \n",
    "Converting the number to a binary vector\n",
    "Ex: \n",
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)\n",
    "tf.Tensor(\n",
    "[[1. 0. 0. 0.]\n",
    " [0. 1. 0. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
    "\"\"\"\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "x_train = np.reshape(x_train,(Ntr,Din))#shaping images into a vector Din=32x32x3\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, K)#initialization\n",
    "b1 = np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "batch_size = Ntr #for the batch size whole dataset is considered\n",
    "\n",
    "iterations =300\n",
    "lr =0.8\n",
    "lr_decay=0.001#learning rate is decreased in each iteration\n",
    "reg =0.5#regularization term which stops growth of weights\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\"\"\"\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    indices = np.arange(Ntr)#generating image\n",
    "    rng.shuffle(indices)\n",
    "    # Forward pass\n",
    "    # Backward pass\n",
    "# Printing accuracies and displaying w as images\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
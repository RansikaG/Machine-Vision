{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "w1: (3072, 10)\n",
      "b1: (10,)\n",
      "0.3124990546290997\n",
      "0.31608315837848333\n",
      "0.2669174327217398\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print('x_train:' , x_train.shape)\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "# Din = 784 # MINIST\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "#https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current\n",
    "x_test = x_test - mean_image\n",
    "\"\"\"In the ytrain it is preliminarily is in numbers just to indicate the particular class tf.keras.utils.to_categorical(y_train, num_classes=K) does is \n",
    "Converting the number to a binary vector\n",
    "Ex: \n",
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)\n",
    "tf.Tensor(\n",
    "[[1. 0. 0. 0.]\n",
    " [0. 1. 0. 0.]\n",
    " [0. 0. 1. 0.]\n",
    " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
    "\"\"\"\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "x_train = np.reshape(x_train,(Ntr,Din))#shaping images into a vector Din=32x32x3\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, K)#initialization\n",
    "b1 = np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "batch_size = Ntr #for the batch size whole dataset is considered\n",
    "\n",
    "iterations =3\n",
    "lr =0.8\n",
    "lr_decay=0.001#learning rate is decreased in each iteration\n",
    "reg =0.5#regularization term which stops growth of weights\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    #indices = np.arange(Ntr)#generating image\n",
    "    #rng.shuffle(indices)\n",
    "    # Forward pass\n",
    "    loss,cache=forward_prop(W=w1,b=b1,X=x_train,Y=y_train,reg=reg)\n",
    "    print(loss)\n",
    "    y_hat=cache[\"y_hat\"]\n",
    "    A=cache[\"A\"]\n",
    "\n",
    "    # Backward pass\n",
    "    dw1,db1=back_prop(A=A,Y_hat=y_hat,W=w1,X=x_train,Y=y_train,reg=reg)\n",
    "    w1=w1-lr*dw1\n",
    "    b1=b1-lr*db1\n",
    "# Printing accuracies and displaying w as images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
      "[1.5 0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)\n",
    "B=[[1,2,1,1],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "mse = np.mean((a - B)**2,axis=1)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "def loss(W,b,X,Y,reg):\n",
    "    print(W.shape,\"W\")\n",
    "    print(b.shape,\"b\")\n",
    "    print(X.shape,\"X\")\n",
    "    print(Y.shape,\"Y\")\n",
    "    prediction=np.dot(X,W)+np.transpose(b)\n",
    "    print()\n",
    "    m=X.shape[0]\n",
    "    mse = np.sum(np.square((Y - prediction)**2))\n",
    "    Loss=mse+ 1/(2*m)*reg*np.sum(W**2)\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.73105858, 0.88079708, 0.73105858, 0.73105858],\n",
       "       [0.5       , 0.73105858, 0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       , 0.73105858, 0.5       ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.73105858]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    z=np.array(z)\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "sigmoid(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,Y,b,W,reg):\n",
    "    #print(W.shape,\"W\")\n",
    "    #print(b.shape,\"b\")\n",
    "    #print(X.shape,\"X\")\n",
    "    #print(Y.shape,\"Y\")\n",
    "    A=np.dot(X,W)+np.transpose(b)\n",
    "    #print(A.shape,\"A\")\n",
    "    y_hat=sigmoid(A)\n",
    "    m=X.shape[0]\n",
    "    #print(m)\n",
    "    mse =1/(2*m)* np.sum(np.square((Y - y_hat)**2))\n",
    "    Loss=mse+ 1/(2*m)*reg*np.sum(W**2)\n",
    "    cache={\"A\":A,\"y_hat\":y_hat}\n",
    "    return Loss,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3072, 10) W\n",
      "(10,) b\n",
      "(50000, 3072) X\n",
      "(50000, 10) Y\n",
      "(50000, 10) A\n",
      "50000\n",
      "0.31249970513070713\n"
     ]
    }
   ],
   "source": [
    "loss,cache=forward_prop(W=w1,b=b1,X=x_train,Y=y_train,reg=reg)\n",
    "print(loss)\n",
    "y_hat=cache[\"y_hat\"]\n",
    "A=cache[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_prop(A,W,X,Y,Y_hat,reg):\n",
    "    m=Y.shape[0]\n",
    "    dy_hat =Y_hat-Y\n",
    "    #print(dy_hat.shape,\"dy_hat\")\n",
    "    dA = dy_hat *sigmoid(A)*(1-sigmoid(A))\n",
    "    #print(dA.shape,\"dA\")\n",
    "    dW =(1/float(m))*(np.dot(X.T, dA)+reg*W)\n",
    "    db=(1/float(m))*np.sum(dA,axis=0)\n",
    "    #print(dW.shape)\n",
    "    #print(db.shape)\n",
    "    return dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[-1.40129866e-03, -5.90441550e-04,  5.67232783e-04, ...,\n",
       "         -4.19029003e-04, -1.52425744e-03, -3.59148941e-03],\n",
       "        [-2.46889924e-03, -2.14337224e-04,  5.00707325e-04, ...,\n",
       "         -5.29186497e-04, -2.62208550e-03, -4.04770045e-03],\n",
       "        [-4.47781285e-03, -3.38515906e-04,  1.68333211e-03, ...,\n",
       "         -4.82374567e-04, -4.54256479e-03, -5.10905912e-03],\n",
       "        ...,\n",
       "        [-3.15761586e-04, -6.91707276e-04,  1.48683954e-04, ...,\n",
       "         -1.33483174e-03,  2.96574120e-03, -1.26495232e-03],\n",
       "        [-9.94508399e-04, -5.53026108e-04, -8.57725095e-06, ...,\n",
       "         -8.92934096e-04,  1.57972060e-03, -9.78336180e-04],\n",
       "        [-2.28748909e-03, -1.20831754e-03,  7.39150279e-04, ...,\n",
       "          5.82655407e-04, -3.43120827e-04, -1.38096240e-03]]),\n",
       " array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]))"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "back_prop(A=A,Y_hat=y_hat,W=w1,X=x_train,Y=y_train,reg=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}